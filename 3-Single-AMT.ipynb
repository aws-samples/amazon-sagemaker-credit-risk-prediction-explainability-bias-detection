{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Single Objective Optimization with Credit Risk Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "#Install dependencies\n",
    "\n",
    "#For Synthetic Data Generation\n",
    "!pip install sdv\n",
    "from sdv.tabular import GaussianCopula\n",
    "\n",
    "from io import StringIO\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import IPython\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import urllib\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.xgboost import XGBoost\n",
    "from sagemaker.s3 import S3Downloader\n",
    "from sagemaker.s3 import S3Uploader\n",
    "from sagemaker import Session\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.xgboost import XGBoostModel\n",
    "from sagemaker.sklearn import SKLearnModel\n",
    "from sagemaker.pipeline import PipelineModel\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "\n",
    "session = Session()\n",
    "bucket = session.default_bucket()\n",
    "prefix = \"sagemaker/sagemaker-amt-credit-risk-model\"\n",
    "region = session.boto_region_name\n",
    "\n",
    "# Define IAM role\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve Biased dataset from Notebook 1 \n",
    "%store -r BiasedData1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = BiasedData1 \n",
    "training_data.info()\n",
    "BiasedData1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the raw training and test CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare raw test data\n",
    "test_data = training_data.sample(frac=0.1)\n",
    "test_data = test_data.drop([\"credit_risk\"], axis=1)\n",
    "test_filename = \"test.csv\"\n",
    "test_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "]\n",
    "test_data.to_csv(test_filename, index=False, header=True, columns=test_columns, sep=\",\")\n",
    "\n",
    "# prepare raw training data\n",
    "credit_columns = [\n",
    "    \"status\",\n",
    "    \"duration\",\n",
    "    \"credit_history\",\n",
    "    \"purpose\",\n",
    "    \"amount\",\n",
    "    \"savings\",\n",
    "    \"employment_duration\",\n",
    "    \"installment_rate\",\n",
    "    \"personal_status_sex\",\n",
    "    \"other_debtors\",\n",
    "    \"present_residence\",\n",
    "    \"property\",\n",
    "    \"age\",\n",
    "    \"other_installment_plans\",\n",
    "    \"housing\",\n",
    "    \"number_credits\",\n",
    "    \"job\",\n",
    "    \"people_liable\",\n",
    "    \"telephone\",\n",
    "    \"foreign_worker\",\n",
    "    \"credit_risk\",\n",
    "]\n",
    "train_filename = \"train.csv\"\n",
    "training_data.to_csv(train_filename, index=False, header=True, columns=credit_columns, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode and Upload Data\n",
    "Here we encode the training and test data. Encoding input data is not necessary for SageMaker Clarify, but is necessary for XGBoost models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw = S3Uploader.upload(test_filename, \"s3://{}/{}/data/test\".format(bucket, prefix))\n",
    "(test_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = S3Uploader.upload(train_filename, \"s3://{}/{}/data/train\".format(bucket, prefix))\n",
    "print(train_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing and feature engineering with SageMaker Processing job\n",
    "\n",
    "We will use SageMaker Processing jobs to perform the preprocessing on the raw data. SageMaker Processing provides prebuilt container for SKlearn which we will use here. We will output a sklearn model that can be used for preprocessing inference requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_processor = SKLearnProcessor(\n",
    "    role=role,\n",
    "    base_job_name=\"sagemaker-amt-credit-risk-processing-job\",\n",
    "    instance_type=\"ml.m5.large\",\n",
    "    instance_count=1,\n",
    "    framework_version=\"0.20.0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can have a look at the preprocessing script prepared to run in the processing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize processing/preprocessor.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NOTE: THIS CELL WILL RUN FOR APPROX. 5-8 MINUTES! PLEASE BE PATIENT. \n",
    "For further documentation on SageMaker Processing, you can refer the documentation [here](https://docs.aws.amazon.com/sagemaker/latest/dg/processing-job.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = \"s3://{0}/{1}/data/train/\".format(bucket, prefix)\n",
    "train_data_path = \"s3://{0}/{1}/data/preprocessed/train/\".format(bucket, prefix)\n",
    "val_data_path = \"s3://{0}/{1}/data/preprocessed/val/\".format(bucket, prefix)\n",
    "model_path = \"s3://{0}/{1}/sklearn/\".format(bucket, prefix)\n",
    "\n",
    "\n",
    "sklearn_processor.run(\n",
    "    code=\"processing/preprocessor.py\",\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name=\"raw_data\", source=raw_data_path, destination=\"/opt/ml/processing/input\"\n",
    "        )\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"train_data\", source=\"/opt/ml/processing/train\", destination=train_data_path\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"val_data\", source=\"/opt/ml/processing/val\", destination=val_data_path\n",
    "        ),\n",
    "        ProcessingOutput(\n",
    "            output_name=\"model\", source=\"/opt/ml/processing/model\", destination=model_path\n",
    "        ),\n",
    "    ],\n",
    "    arguments=[\"--train-test-split-ratio\", \"0.2\"],\n",
    "    logs=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train XGBoost Model\n",
    "In this step, we will train an XGBoost model on the preprocessed data. We will use our own training script with the built-in XGBoost container provided by SageMaker.\n",
    "\n",
    "Alternatively, for your own use case, you can also bring your own model (trained elsewhere) to SageMaker for processing with SageMaker Clarify\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pygmentize training/train_xg_amt.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up XGBoost Estimator\n",
    "\n",
    "Next, let us set up:    \n",
    " 1. Pre-defined values for Hyperparameters for XGBoost algorithm\n",
    " 1. XGBoost Estimator for SageMaker\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.1\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"silent\": \"1\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"eval_metric\": \"auc\",\n",
    "    \"early_stopping_rounds\": \"20\",\n",
    "    \"output_data_dir\": \"/opt/ml/output/data/\",\n",
    "}\n",
    "\n",
    "entry_point = \"train_xg_amt_single.py\"\n",
    "source_dir = \"training/\"\n",
    "output_path = \"s3://{0}/{1}/{2}\".format(bucket, prefix, \"xgb_model\")\n",
    "code_location = \"s3://{0}/{1}/code\".format(bucket, prefix)\n",
    "\n",
    "estimator = XGBoost(\n",
    "    entry_point=entry_point,\n",
    "    source_dir=source_dir,\n",
    "    output_path=output_path,\n",
    "    code_location=code_location,\n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=\"ml.c5.xlarge\",\n",
    "    instance_count=1,\n",
    "    framework_version=\"0.90-2\",\n",
    "    py_version=\"py3\",\n",
    "    role=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SageMaker AMT (HPO)\n",
    "\n",
    "Now it's time to run the HPO job to train and find the best model \n",
    "\n",
    "#### NOTE: THIS CELL WILL RUN FOR APPROX. 5-8 MINUTES! PLEASE BE PATIENT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Model Tuning (HPO)\n",
    "\n",
    "# output_data_dir = 's3://sagemaker-us-east-2-921553072635/sagemaker/sagemaker-amt-credit-risk-model/data/output/'\n",
    "\n",
    "from sagemaker.tuner import IntegerParameter, CategoricalParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {'eta': ContinuousParameter(0, 1),\n",
    "                        'min_child_weight': IntegerParameter(1, 10),\n",
    "                        'gamma': IntegerParameter(1, 5),\n",
    "                        'max_depth': IntegerParameter(1, 10)}\n",
    "\n",
    "objective_metric_name = 'validation:auc'\n",
    "\n",
    "tuner = HyperparameterTuner(estimator,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "                            max_jobs=500, # 500\n",
    "                            max_parallel_jobs=10, #16\n",
    "                           )\n",
    "\n",
    "tuning_job_name = \"xgb-tuner-{}\".format(strftime(\"%d-%H-%M-%S\", gmtime()))\n",
    "\n",
    "# inputs = {'train': train_data_path, 'validation': val_data_path, 'output_data_dir': output_data_dir}\n",
    "\n",
    "inputs = {'train': train_data_path, 'validation': val_data_path}\n",
    "\n",
    "tuner.fit(inputs, job_name=tuning_job_name)\n",
    "\n",
    "tuner.wait()\n",
    "\n",
    "tuner_metrics = sagemaker.HyperparameterTuningJobAnalytics(tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The best Area Under Curve (AUC) score, alongside the Disparate Impact was found by going into the SageMaker logs where they are saved. You can find the logs by following the image guide below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the SageMaker console page navigate the left menu and find Training -> Hyperparameter Tuning Jobs. That will bring up all the recent Tuuning jobs and you can click the latest one. \n",
    "![Step1](images/Step1A.jpg)\n",
    "\n",
    "Scrolling down the tuning job page will bring you to “Best training job summary”. Here you can see the name of the best training job and the optimized value of the metric specified. In this case you can see that the AUC value is optimized at 0.91. Click on the best training job name.\n",
    "![Step2](images/Step2A.jpg)\n",
    "\n",
    "Scrolling down the page of the best training job, you will find a section under “Monitor” called “View logs”. Click on this to take you to CloudWatch logs.\n",
    "![Step3](images/Step3A.jpg)\n",
    "\n",
    "Scrolling down this current page you will encounter a section called “Log streams”. Click the name of your training job under this section.\n",
    "![Step4](images/Step4A.jpg)\n",
    "\n",
    "On this current page we can scroll all the way down and view all of the values the AI model has tried, the final values are at the bottom and are the optimized ones. \n",
    "![Step5](images/Step5A.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best AUC Score for single Metric Optimization \n",
    "auc_score = 0.91\n",
    "#Acompanying Disparate Impact\n",
    "di = 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As can be seen we have a very high AUC Score which is due to the optimization of the tuning job. The tuning was not optimized for DI therefor the value is not the best (lowest) as can be. Please refer back to these values as you will require them to complete the lab in the next notebook.  \n",
    "\n",
    "### You may now move onto \"4-Multi-AMT.ipynb\" to explore Multi Objective Optimization tuning jobs to optimize both AUC & DI"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-2:429704687514:image/sagemaker-data-science-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
